import React, { useEffect, useRef, useState } from 'react';
import * as THREE from 'three';
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader';
import * as facemesh from '@tensorflow-models/facemesh';
import '@tensorflow/tfjs';

const FaceTrackingGlasses = () => {
  const videoRef: any = useRef(null);
  const canvasRef: any = useRef(null);
  const [glasses, setGlasses] = useState(null);

  useEffect(() => {
    const loadFaceMesh = async () => {
      await setupCamera();
      initThreeJS();

      // videoRef.current.onload(async () => {
      //   const model = await facemesh.load();
      //   detectFace(model);
      // });
    };

    const setupCamera = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' },
      });

      if (videoRef?.current) {
        (videoRef.current as any).srcObject = stream;
        await new Promise((resolve) => {
          (videoRef.current as any).onloadedmetadata = () => {
            (videoRef.current as any).play();
            resolve(true);
          };
        });
      }
    };

    const initThreeJS = () => {
      const renderer = new THREE.WebGLRenderer({
        canvas: canvasRef.current,
        alpha: true,
      });
      renderer.setSize(window.innerWidth, window.innerHeight);

      const scene = new THREE.Scene();
      const camera = new THREE.PerspectiveCamera(
        70,
        window.innerWidth / window.innerHeight,
        0.01,
        1000
      );
      camera.position.z = 5;

      console.info('before load gltf');
      // Load glasses model
      const loader = new GLTFLoader();
      loader.load(
        '/Excellent_1803_whitetransparant_2021.gltf',
        (gltf: any) => {
          console.info('gltf.scene', gltf.scene);
          const modelGlasses = gltf.scene;
          modelGlasses.scale.set(0.1, 0.1, 0.1);
          scene.add(modelGlasses);
          setGlasses(modelGlasses); // Save reference to glasses
        },
        undefined,
        (error: any) => console.error('Error loading glasses model:', error)
      );
      console.info('after load gltf');

      // Save renderer, scene, camera in refs
      canvasRef.current.renderer = renderer;
      canvasRef.current.scene = scene;
      canvasRef.current.camera = camera;
    };

    const detectFace = async (model: any) => {
      if (!videoRef.current) {
        return true;
      }
      if ((videoRef.current as any).readyState === 4) {
        try {
          console.info('before predictions');
          const predictions = await model.estimateFaces({
            input: videoRef.current,
          });
          console.info('after predictions', predictions);
          if (predictions.length > 0) {
            const keypoints = predictions[0].scaledMesh;
            const leftEye = keypoints[33];
            const rightEye = keypoints[263];

            // Update glasses position based on eye midpoint
            if (glasses) {
              const eyeMidpoint = [
                (leftEye[0] + rightEye[0]) / 2,
                (leftEye[1] + rightEye[1]) / 2,
                (leftEye[2] + rightEye[2]) / 2,
              ];
              (glasses as any).position.set(
                eyeMidpoint[0] * 0.01,
                -eyeMidpoint[1] * 0.01,
                -eyeMidpoint[2] * 0.01
              );
            }
          }

          // Render the scene
          canvasRef.current.renderer.render(
            canvasRef.current.scene,
            canvasRef.current.camera
          );
          requestAnimationFrame(() => detectFace(model));
        } catch(err) {
          //
        }
      }
    };

    // Start face mesh detection
    loadFaceMesh();

    const handleVideoLoaded = async () => {
      console.info('handleVideoLoaded');
      // Pastikan video sudah siap sebelum memprosesnya
      if (videoRef.current) {
        try {
          const model = await facemesh.load();
          console.info('model', model);
          // detectFace(model);
        } catch (error) {
          console.error('Error processing video frame:', error);
        }
      }
    };
    // Tambahkan event listener setelah komponen mounting
    const videoElement = videoRef.current;
    if (videoElement) {
      videoElement.addEventListener('loadeddata', handleVideoLoaded);
    }

    return () => {
      // Cleanup resources on unmount
      videoRef.current && ((videoRef.current as any).srcObject = null);
    };
  }, [glasses]);

  return (
    <div style={{ position: 'relative' }}>
      <video ref={videoRef} autoPlay playsInline width="640" height="480" />
      <canvas
        ref={canvasRef}
        style={{
          position: 'absolute',
          top: 0,
          left: 0,
          width: 500,
          height: 500,
        }}
      />
    </div>
  );
};

export default FaceTrackingGlasses;
